# AutoU â€” ClassificaÃ§Ã£o Inteligente de Eâ€‘mails

AplicaÃ§Ã£o web para **classificar e-mails** e **sugerir respostas automÃ¡ticas** (PT/EN) usando NLP + IA.

---

## âœ¨ Principais features
- Upload de `.txt` e `.pdf` ou colagem de texto.
- ClassificaÃ§Ã£o **Produtivo** Ã— **Improdutivo** com subintenÃ§Ãµes (Status, Erro, Acesso, Anexo, Encerramento, Suporte, Agradecimento, SaudaÃ§Ã£o, Geral).
- Resposta sugerida **PT/EN** (templates locais com opÃ§Ã£o de usar OpenAI/HuggingFace).
- HeurÃ­sticas para anexos/evidÃªncias e *safetyâ€‘latch* que corrige a categoria a partir da subintenÃ§Ã£o.
- UI moderna (Tailwind), whitelabel (nome/logo editÃ¡veis).

---

## ğŸ§° Stack
**Backend:** Flask + scikitâ€‘learn â€¢ **IA (opcional):** OpenAI / HuggingFace â€¢ **Frontend:** HTML + Tailwind â€¢ **PDF:** PyMuPDF/PyPDF2

---

## ğŸš€ Como rodar localmente

> **Importante:** Neste projeto o servidor local Ã© iniciado com `python run.py` (e nÃ£o `flask run`).  
> Se vocÃª quiser usar `flask run`, veja a nota mais abaixo.

1) Clone e entre no projeto
```bash
git clone https://github.com/LuckyLee89/Desafio-AutoU.git
cd Desafio-AutoU
```

2) Crie e ative o ambiente
```bash
python -m venv .venv
# Windows
.venv\Scripts\activate
# macOS / Linux
source .venv/bin/activate
```

3) Instale
```bash
pip install -r requirements.txt
```

4) Configure variÃ¡veis (opcional)  
Crie seu `.env` a partir do exemplo:
```bash
cp .env.example .env
```
- Para usar o modo local (padrÃ£o), deixe `PROVIDER=local`.
- Para usar OpenAI/HuggingFace, preencha as chaves no `.env`.

5) **Inicie o app**
```bash
python run.py
```
Acesse: http://localhost:8080

### OPCIONAL â€” usando `flask run`
Se quiser iniciar via CLI do Flask, defina as variÃ¡veis de app/ambiente e rode:
```bash
# Windows (PowerShell)
$env:FLASK_APP="wsgi.py"; $env:FLASK_ENV="development"; flask run --port 8080

# macOS / Linux (bash/zsh)
export FLASK_APP=wsgi.py FLASK_ENV=development
flask run --port 8080
```
> Em alguns ambientes Windows, o *launcher* do `flask` pode nÃ£o estar no PATH do venv â€” por isso indicamos `python run.py` como caminho padrÃ£o.

---

## â˜ï¸ Deploy (Render / Railway / etc.)

Arquivos jÃ¡ incluÃ­dos:
- **Procfile** â†’ `web: gunicorn wsgi:app --workers 2 --threads 8 --timeout 60`
- **runtime.txt** â†’ `python-3.11.9`
- **wsgi.py** â†’ ponto de entrada do Gunicorn

### Render (Web Service)
- Build command: `pip install -r requirements.txt`
- Start command: `gunicorn wsgi:app --workers 2 --threads 8 --timeout 60`
- Env vars: copie as de `.env.example` conforme necessÃ¡rio (PROVIDER, chaves etc.).

---

## ğŸ“ Estrutura
```
app/
 â”œâ”€ routes/            # Endpoints Flask
 â”œâ”€ services/          # Classifier, IA provider, respostas
 â”œâ”€ utils/             # ExtraÃ§Ã£o de texto PDF/TXT
 â”œâ”€ templates/         # index.html (UI)
 â””â”€ static/            # app.js, style.css, assets
models/                # modelo sklearn (joblib)
intents_config.json    # sinÃ´nimos + fastpath
run.py                 # entrada local (python run.py)
wsgi.py                # entrada produÃ§Ã£o (gunicorn wsgi:app)
Procfile               # start do web service
requirements.txt
runtime.txt
README.md
```

---

## ğŸ§ª Teste rÃ¡pido
- Upload de um `.txt` com:  
  `Bom dia, poderiam informar o status do chamado 123456?`
- Verifique: subintenÃ§Ã£o **Status**, categoria **Produtivo**, resposta automÃ¡tica coerente.
- Teste um PDF â€œgenÃ©ricoâ€ (contrato, etc.) para ver resposta â€œsem aÃ§Ã£o necessÃ¡riaâ€.

---

## ğŸ“¹ VÃ­deo (3â€“5 min)
1. **IntroduÃ§Ã£o** (30s) â€” objetivo do desafio.  
2. **Demo** (3m) â€” upload, classificaÃ§Ã£o, resposta sugerida.  
3. **TÃ©cnico** (1m) â€” pipeline NLP, fastpath JSON, IA providers.  
4. **ConclusÃ£o** (30s) â€” aprendizados e prÃ³ximos passos.

---

## ğŸ“œ LicenÃ§a
Uso acadÃªmico / demonstraÃ§Ã£o.
